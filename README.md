# ü§ñ Business Agents

**Production-ready multi-agent systems for business automation. 100% local. Zero API costs.**

> Most AI agent tutorials cost $50+/month in API fees. This runs entirely on your machine using Ollama. Your data never leaves your computer.

---

## What's Inside

| Agent | What It Does | Status |
|-------|--------------|--------|
| üóìÔ∏è **Meeting Prep Agent** | Researches attendees, drafts agendas, suggests talking points | ‚úÖ Ready |
| üîç **Lead Research Agent** | Takes a company name, returns firmographics + key contacts | üöß Coming |
| üìÑ **Document Q&A Agent** | Chat with your PDFs and docs using RAG | üöß Coming |
| ‚úâÔ∏è **Email Drafter Agent** | Context-aware email responses | üöß Coming |
| üìä **Competitive Intel Agent** | Monitor competitors, summarize changes | üöß Coming |

---

## Why This Exists

I built these because:

1. **Most agent examples are toys** - They demo well but break in production
2. **API costs add up fast** - $0.01 per call √ó 1000 calls/day = real money
3. **Business context matters** - Generic agents don't understand your workflows

These agents are designed for **real business use cases** with proper error handling, logging, and extensibility.

---

## Quick Start

### Prerequisites

- Python 3.10+
- [Ollama](https://ollama.com/) installed locally

### 1. Clone and Install

```bash
git clone https://github.com/chris-damien/autogen-business-agents.git
cd autogen-business-agents
pip install -r requirements.txt
```

### 2. Pull a Local Model

```bash
# Recommended: Llama 3.2 (good balance of speed + quality)
ollama pull llama3.2

# Alternative: Mistral (faster, slightly less capable)
ollama pull mistral
```

### 3. Run Your First Agent

```bash
python examples/meeting_prep_example.py
```

---

## Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    YOUR APPLICATION                      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                      ‚îÇ
                      ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                   CREW ORCHESTRATOR                      ‚îÇ
‚îÇ  - Manages agent handoffs                               ‚îÇ
‚îÇ  - Handles task delegation                              ‚îÇ
‚îÇ  - Aggregates results                                   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                      ‚îÇ
        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚ñº             ‚ñº             ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   AGENT 1    ‚îÇ ‚îÇ   AGENT 2    ‚îÇ ‚îÇ   AGENT 3    ‚îÇ
‚îÇ  Researcher  ‚îÇ ‚îÇ   Analyst    ‚îÇ ‚îÇ    Writer    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ                ‚îÇ                ‚îÇ
       ‚ñº                ‚ñº                ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ    TOOLS     ‚îÇ ‚îÇ    TOOLS     ‚îÇ ‚îÇ    TOOLS     ‚îÇ
‚îÇ - Web Search ‚îÇ ‚îÇ - Calculator ‚îÇ ‚îÇ - Formatter  ‚îÇ
‚îÇ - Scraper    ‚îÇ ‚îÇ - Summarizer ‚îÇ ‚îÇ - Templates  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                      ‚îÇ
                      ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                 OLLAMA (LOCAL LLM)                       ‚îÇ
‚îÇ  - llama3.2 / mistral / codellama                       ‚îÇ
‚îÇ  - Runs on YOUR machine                                 ‚îÇ
‚îÇ  - No API costs, no rate limits                         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## Project Structure

```
autogen-business-agents/
‚îú‚îÄ‚îÄ agents/                 # Agent definitions
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ meeting_prep.py     # Meeting preparation crew
‚îÇ   ‚îú‚îÄ‚îÄ lead_research.py    # Lead/company research crew
‚îÇ   ‚îî‚îÄ‚îÄ base.py             # Base agent configuration
‚îú‚îÄ‚îÄ tools/                  # Custom tools for agents
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ search.py           # Web search tools
‚îÇ   ‚îî‚îÄ‚îÄ formatters.py       # Output formatting
‚îú‚îÄ‚îÄ configs/                # Configuration files
‚îÇ   ‚îî‚îÄ‚îÄ models.py           # LLM configuration
‚îú‚îÄ‚îÄ examples/               # Ready-to-run examples
‚îÇ   ‚îî‚îÄ‚îÄ meeting_prep_example.py
‚îú‚îÄ‚îÄ docs/                   # Documentation
‚îÇ   ‚îî‚îÄ‚îÄ ARCHITECTURE.md
‚îú‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ .env.example
‚îî‚îÄ‚îÄ README.md
```

---

## Configuration

### Using Ollama (Default - Free)

No configuration needed. Just ensure Ollama is running:

```bash
ollama serve
```

### Using OpenAI (Optional)

If you prefer OpenAI, create a `.env` file:

```bash
cp .env.example .env
# Edit .env and add your OPENAI_API_KEY
```

---

## Extending

### Adding a New Agent

1. Create a new file in `agents/`
2. Define your agents and their roles
3. Create a Crew that orchestrates them
4. Add an example in `examples/`

See `agents/meeting_prep.py` for a complete example.

### Adding Custom Tools

Tools give agents capabilities beyond text generation:

```python
from crewai.tools import tool

@tool("Company Lookup")
def lookup_company(company_name: str) -> str:
    """Looks up company information from public sources."""
    # Your implementation here
    return company_info
```

---

## Roadmap

- [x] Meeting Prep Agent
- [ ] Lead Research Agent
- [ ] Document Q&A Agent (RAG)
- [ ] Email Drafter Agent
- [ ] Competitive Intel Agent
- [ ] Slack Integration
- [ ] API wrapper for all agents

---

## Why CrewAI?

I evaluated AutoGen, LangGraph, and CrewAI. Here's why I chose CrewAI for this project:

| Framework | Pros | Cons |
|-----------|------|------|
| **CrewAI** | Simple API, great docs, fast to ship | Less flexible than LangGraph |
| AutoGen | Microsoft backing, enterprise feel | Steeper learning curve |
| LangGraph | Most flexible, fine-grained control | Complex for simple use cases |

For business automation agents, **simplicity wins**. These agents need to be maintainable by teams, not just AI engineers.

---

## Contributing

PRs welcome. Please:

1. Keep agents focused on real business use cases
2. Include working examples
3. Test with Ollama (free tier must work)

---

## License

MIT - Use it however you want.

---

## About

Built by [Chris Damien](https://linkedin.com/in/chris-damien) as part of my work helping businesses automate with AI.

**More resources:**
- [LinkedIn](https://linkedin.com/in/chris-damien) - I write about AI automation weekly
- [Other Projects](https://github.com/chris-damien) - More automation tools

---

*If this helped you, star the repo ‚≠ê*
